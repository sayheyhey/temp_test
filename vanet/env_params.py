TIME_SLOT = 1  # s
REQUEST_DENSE = 10  # request per TIME_SLOT

ZIPF_BELTA = 0.56  # larger belta introduces more skewed content popularity distribution
KERNEL_ALPHA = 0.5  # relect the average cosine similarity among vehicles
CONTENT_LIBRARY_SIZE = 100  # num of different content files
ENCODED_SEGMENTS_UNITS_MAX, ENCODED_SEGMENTS_UNITS_MIN = 1, 1
SEGMENT_UNIT_SIZE_MAX, SEGMENT_UNIT_SIZE_STEP, SEGMENT_UNIT_SIZE_MIN = 20, 5, 5  # MB
ENCODED_SEGMENTS_UNITS_MID, SEGMENT_UNIT_SIZE_MID = (ENCODED_SEGMENTS_UNITS_MIN + ENCODED_SEGMENTS_UNITS_MAX) / 2, (SEGMENT_UNIT_SIZE_MAX + SEGMENT_UNIT_SIZE_MIN) / 2
VEH_CACHE_SIZE, RSU_CACHE_SIZE = 4 * (int(ENCODED_SEGMENTS_UNITS_MID * SEGMENT_UNIT_SIZE_MID)), 15 * (int(ENCODED_SEGMENTS_UNITS_MID * SEGMENT_UNIT_SIZE_MID))  # pyht
VEH_RANGE, RSU_RANGE, MBS_RANGE = 5, 20, 50  # m
BANDWIDTH_V2V, BANDWIDTH_V2R, BANDWIDTH_V2I, BANDWIDTH_R2R = 30, 30, 10, 100  # MHz
P_VEH, P_RSU, P_MBS = 0.25, 1, 20  # Watt (24, 30, 43dBm)
NOISE_POWER = 10 ** (-14)  # Watt
PATHLOSS_CONSTANT = 10 ** (-2)
PATHLOSS_EXPONENT = 4

CACHE_ALGS = [      # algs order aligned with 'cache_delegate_list' in main.py
    'LRU',
    'LFU',
    # 'MPC Cache Algorithm',
    'GCP',
    'RC',
    # 'GDSF Cache Algorithm',
    'DRL'
]

METRICS = ['Successful Handled Request Ratio', 'Cache Hit Ratio', 'Average Request Response Time']
SLIDING_WINDOW_SIZE = 10

RSU_DECISION_INTERVAL = int(20 * ENCODED_SEGMENTS_UNITS_MID)  # cache miss cnt

# feature normalization
RSU_X_MAX, RSU_X_MIN, RSU_Y_MAX, RSU_Y_MIN = 1400, 600, 1200, 800
VEH_X_MAX, VEH_X_MIN, VEH_Y_MAX, VEH_Y_MIN = 100, 0, 100, 0
VEH_CUR_REQUEST_CNT_MAX = 10
DECISION_INTERVAL_MAX = 500
NEIGHBOR_RSU_CNT_MAX, NEIGHBOR_VEH_CNT_MAX = 4, 100
NEW_SEG_CACHE_CNT_MAX = NEW_CONTENT_CACHE_CNT_MAX = 50
CACHE_HIT_CNT_MAX = 10
LOCAL_REQUEST_MAX = 10
REMOTE_REQUEST_MAX = 20
UNABLE_REQUEST_MAX = 300
NEW_CONTENT_UNABLE_REQUEST_MAX = 100
